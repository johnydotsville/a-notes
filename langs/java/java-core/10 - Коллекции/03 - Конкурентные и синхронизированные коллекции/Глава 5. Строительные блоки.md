# 5.1  Syncronized collection

Синхронизированные коллекции включают в себя Vector и Hashtable, а также разные синхронизированные обертки, получаемые с помощью фабричных методов Collections.syncronizedXxx. В этих классах ПБ достигается за счет инкапсуляции состояния и объявление всех публичных методов синхронизированными, так что только один поток за раз может работать с состоянием.

## 5.1.1 Problems with syncronized collections

Проблемы синхронизированных коллекций (СхК).

СхК являются ПБ, но иногда может требоваться дополнительная блокировка в клиентском коде, чтобы защитить составные действия, такие как итерация, навигация (поиск элемента за каким-то элементом по заданному условию) и операции по условию ("проверь-потом-действуй", например "добавить, если отсутствует"). Технически, СхК остаются ПБ и без дополнительных клиентских блокировок, однако могут вести себя не так, как вы ожидаете, в случае конкурентной модификации. Пример:

```java
public static Object getLast(Vector list) {
    int lastIndex = list.size() - 1;
    return list.get(lastIndex);
}

public static void deleteLast(Vector list) {
    int lastIndex = list.size() - 1;
    list.remove(lastIndex);
}
...
for (int i = 0; i < vector.size(); i++)
    doSomething(vector.get(i));
```

Проблема в том, что при вызове getLast может произойти разрыв между вычислением индекса последнего элемента и собственно извлечением элемента. В этот разрыв другой поток может удалить последний элемент и тогда getLast приведет к исключению ArrayIndexOutOfBoundsException. Аналогично и с итерацией.

Добавление клиентского замка решает проблему:

```java
public static Object getLast(Vector list) {
    synchronized (list) {
        int lastIndex = list.size() - 1;
        return list.get(lastIndex);
    }
}

public static void deleteLast(Vector list) {
    synchronized (list) {
        int lastIndex = list.size() - 1;
        list.remove(lastIndex);
    }   
}
...
synchronized (vector) {
    for (int i = 0; i < vector.size(); i++)
        doSomething(vector.get(i));
}
```

## 5.1.2 Iterators and ConcurrentModificationException

Мы использовали Vector в примерах для понятности, хотя он считается устаревшим классом коллекции. Но даже более современные коллекции не решают проблему составных действий. Стандартный способ обхода коллекций - это использовать Iterator, либо явно, либо через "for-each" синтаксис, появившийся в Java 5.0 Итераторы не избавляют нас от необходимости блокировать коллекции на время обхода в случае, если другие потоки могут конкурентно вносить изменения в коллекцию. Синхронизированные коллекции не рассчитаны на конкурентную модификацию и возвращают fail-fast итераторы. Это такие итераторы, которые выбрасывают исключение ConcurrentModificationException, если обнаруживают, что коллекция изменилась с момента начала итерации.

Итого, существует два способа обхода проблемы модификации коллекции во время итерации:

* Блокировать коллекцию. Может быть неприемлемо, если коллекция большая и действия, производимые над элементом во время итерации, занимают много времени. Тогда другие потоки могут ждать очень долго и производительность будет низкая.
* Делать копию коллекции перед итерацией. Опять же, если коллекция большая, это может занять много времени.

## 5.1.3 Hidden iterators

Скрытые итераторы - это когда итерация осуществляется неявно. Мы сами вроде бы ничего не пишем, но какие-то используемые нами операции приводят к итерации:

```java
public class HiddenIterator {

    @GuardedBy("this")
    private final Set<Integer> set = new HashSet<Integer>();

    public synchronized void add(Integer i) { 
        set.add(i); 
    }
    public synchronized void remove(Integer i) { 
        set.remove(i); 
    }

    public void addTenThings() {
        Random r = new Random();
        for (int i = 0; i < 10; i++)
            add(r.nextInt());
        System.out.println("DEBUG: added ten elements to " + set);  // <-- Скрытая итерация
    }
    
}
```

Здесь, чтобы сформировать строковое представление множества, проводится итерация по его элементам и во время нее может выскочить ConcurrentModificationException, т.к. метод println не обернут в синхронизацию.

Методы, которые используют итерацию под капотом: hashCode, equals, containsAll, removeAll, retainAll, конструкторы, принимающие коллекции, и т.д. В общем, скрытая итерация может поджидать на каждом углу.

# 5.2 Concurrent collections

Конкурентные коллекции как более производительная альтернатива синхронизированным коллекциям. В синхронизированных доступ к состоянию просто блокирует потоки, а в конкурентных все более продуманно.

* ConcurrentHashMap - замена синхронизированным реализациям Map, основанных на хэш-таблицах

* Интерфейс ConcurrentMap - добавляет составные действия вроде "добавить-если-отсутствует", заменить, удалить по условию

* ConcurrentSkipListMap

* ConcurrentSkipListSet

* CopyOnWriteArrayList - замена синхронизированным реализациям листа, где обход является превалирующей операцией

* CopyOnWriteArraySet

* Queue - задумана для временного хранения элементов, пока они ждут обработки. Операции в queue не блокирующие - если элемента нет, возвращается null. Несколько реализаций:

  * ConcurrentLinkedQueue - классическая FIFO
  * PriorityQueue - очередь, где элементы автоматически занимают место на основе своего приоритета (natural ordering наверное)

  LinkedList тоже реализует Queue, но у других классов выше производительность за счет выпиливания доступа по индексу.

* BlockingQueue - реализует операции добавления и получения с блокированием, т.е. в случае отсутствия элементов вызывающий поток будет ждать, пока они появятся. А в случае когда все слоты заняты, поток будет ждать, пока они появятся. Удобно для реализации задач производителя-потребителя.

## 5.2.1 ConcurrentHashMap

В отличие от обычных синхронизированных коллекций, эта использует более продвинутый механизм блокирования, называемый *lock striping* (глава 11.4.2). В итоге она поддерживает неограниченно много конкурентных потоков-"читателей", ограниченное количество конкурентных "писателей", а также "читатели" и "писатели" могут работать конкурентно. В однопоточных программах эта версия мэпы имеет лишь незначительное ухудшение производительности.

Эта коллекция, как и другие конкурентные, возвращает *weakly-consistent* итератор, который не выбрасывает ConcurrentModificationException. Он спокойно переносит конкурентную модификацию коллекции и может (но не обязан, так что не всегда) видеть внесенные изменения.

Такие операции как size, isEmpty работают "приблизительно", т.е. на момент получения результата он уже может измениться. Это цена за производительные операции get, put, remove, containsKey.

## 5.2.2 Additional atomic Map operations

С ConcurrentHashMap мы не сможем использовать клиентскую блокировку (client-side locking, т.е. с помощью замка организовать потоку эксклюзивный доступ к CHM), чтобы организовать атомарные операции вроде "добавить-если-отсутствует", но в ней уже есть все подобные операции.

TODO: почему не можем сделать клиентскую блокировку? Просто ведь в синхронизированный блок доступ к мапе делаем и все, разве нет?

## 5.2.3 CopyOnWriteArrayList

Замена синхронизированному списку, избавляет от нужды блокировать или копировать список для итерации. Изменение коллекции он реализует через создание копии коллекции и ее повторной публикации при каждом ее изменении. Итератор хранит ссылку на подлежащий массив на момент своего создания. Сам же список после создания копии массива меняет у себя ссылку и таким образом начинает хранить уже модифицированную коллекцию. Так что вновь созданные итераторы уже пойдут по новому массиву, а старые итераторы - по старому, на который сохранили ссылку при своем создании.

TODO: посмотреть бы исходники

Этот вид списка подходит для случаев, когда итерация - превалирующая операция, а добавление \ удаление - более редкая. Например, система уведомлений. Регистрация получателей здесь явно происходит реже, чем их уведомление о событиях. В основном нужно обходить список и вызывать получателей.

# 5.3 Blocking queues and the produce-consumer pattern

Блокирующая очередь обеспечивает блокировку при операциях put и take в случаях, когда очередь, соответственно, полна или пуста. Очереди бывают ограниченные и неограниченные. В неограниченных размер очереди бесконечный, соответственно put никогда не приводит к блокировке.

БО поддерживают паттерн производитель-потребитель, который заключается в разделении понятий "выполнение работы" и "работа, которую нужно сделать". Задания кладутся в очередь и выполняются по мере возможности.

Один из наиболее типичных сценариев поставщик-потребитель - это пул потоков, связанный с очередью. Он реализован в Executor (глава 6 и 8).

Пример паттерна - два человека, один моет тарелки, другой - вытирает. Когда мойщик вымыл тарелку, он ставит ее в тарельницу, а вытиральщик берет ее оттуда и вытирает. Если мойщик моет медленно, то вытиральщик будет ждать, пока появятся тарелки. Тарельница в этом случае - это очередь, мойщик - производитель, а вытиральщик - потребитель. Вытиральщик может быть и производителем, если сухие тарелки он передает, например, официанту, который кладет на них заказы.

Метод offer возвращает статус провала, если элемент нельзя поместить в очередь из-за того, что она уже полна.

Стандартная библиотека содержит несколько реализаций БО:

* LinkedBlockingQueue
* ArrayBlockingQueue
* PriorityBlockingQueue
* SyncronousQueue - здесь особенно будет интересно разобраться, это странная штука

## 5.3.1 Example: desktop search

Пример заключается в том, что задача поиска разделяется на две подзадачи: собственно сканирование файловой системы (DiskCrawler класс) и индексирование для дальнейшего поиска (Indexer). Разделение задачи по паттерну поставщик-потребитель делает подзадачи прозрачнее и улучшает производительность, т.к. сканирование ФС - это IO-ориентированная операция, а индексирование - CPU-ориентированная. Последовательное выполнение такого рода задач работает медленнее.

Условная реализация: 

Поисковик:

```java
public class FileCrawler implements Runnable {

    private final BlockingQueue<File> fileQueue;
    private final FileFilter fileFilter;
    private final File root;
    ...
    public void run() {
        try {
            crawl(root);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
    
    private void crawl(File root) throws InterruptedException {
        File[] entries = root.listFiles(fileFilter);
        if (entries != null) {
            for (File entry : entries)
                if (entry.isDirectory())
                    crawl(entry);
                else if (!alreadyIndexed(entry))
                    fileQueue.put(entry);
        }
    }
    
}
```

Индексатор:

```java
public class Indexer implements Runnable {

    private final BlockingQueue<File> queue;

    public Indexer(BlockingQueue<File> queue) {
        this.queue = queue;
    }

    public void run() {
        try {
            while (true)
                indexFile(queue.take());
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
    
}
```

Связывание вместе и запуск работы:

```java
public static void startIndexing(File[] roots) {
    BlockingQueue<File> queue = new LinkedBlockingQueue<File>(BOUND);
    FileFilter filter = new FileFilter() {
        public boolean accept(File file) { return true; }
    };

    for (File root : roots)
        new Thread(new FileCrawler(queue, filter, root)).start();

    for (int i = 0; i < N_CONSUMERS; i++)
        new Thread(new Indexer(queue)).start();
}
```

В данном виде программа никогда не завершится, т.к. потоки потребителя используют бесконечный цикл. В главе 7 это будет переделано.

## 5.3.2 Serial thread confinement

*Последовательное ограничение одним потоком*??? (STC, ПООП) TODO: поискать, где это реализовано

Реализации блокирующей очереди в java.util.concurrent содержат внутреннюю синхронизацию, чтобы безопасно публиковать объекты от производящего потока к потребляющему.

Для изменяемых объектов паттерн П-П и БО используют *последовательное ограничение одним потоком* для передачи владения объектом от поставщика к потребителю. Ограниченный потоком объект владеется эксклюзивно одним потоком, но это владение может быть передано через безопасную публикацию, при которой только один другой поток получит доступ к объекту, а опубликовавший поток не будет стучаться после передачи владения. Безопасная публикация гарантирует, что состояние объекта видно новому владельцу, и поскольку исходный владелец больше не будет трогать объект, то объект ограничен новым потоком. И он может его спокойно изменять, т.к. имеет эксклюзивный доступ.

Пулы объектов используют ПООП, чтобы "одолжить" потоку объект. Поскольку пулы используют внутреннюю синхронизацию для безопасной публикации объектов, а клиенты самостоятельно не публикуют объект и не используют его после возвращения в пул, то владение может быть безопасно передано из одного потока в другой.

## 5.3.3 Deques and work stealing

Java 6 предоставляет еще две коллекции: Deque и BlockingDeque. Дек, она же double-ended queue обеспечивает эффективное добавление и удаление с обоих концов очереди. Эти очереди связаны с паттерном *work stealing*. У шаблона производитель-потребитель есть одна общая очередь для всех потребителей; в шаблоне кража работы у каждого потребителя - свой дек. Если потребитель исчерпал свой дек, он может взять работу из хвоста чужого дека. WS может быть более масштабируемым, чем традиционный П-П шаблон, потому что работяги не борются за общую очередь; большую часть времени они работают только со своим деком, сокращая состязание. Когда работяге нужно получить доступ к чужой очереди, он делает это с хвоста, а не с головы, что уменьшает состязание.

WS хорошо подходит для решения задач, где потребители являются еще и производителями - когда выполнение порции работы выливается в выполнение другой работы. Например, обработка страницы в поисковике выливается в обнаружение новых страниц, которые нужно обработать. Или множество алгоритмов на обход графов, вроде маркировки кучи в процессе сборки мусора, могут быть эффективно распараллелены, используя WS. Когда работяга обнаруживает новую порцию работы, он помещает ее в конец собственного дека (или наоборот в паттерне *work sharing* - в конец дека другого работяги); когда дек пуст, он ищет работу в конце чужого дека, удостоверяясь, что все работяги остаются в работе.

# 5.4 Blocking and interruptible methods

Потоки могут блокироваться, или иными словами приостанавливаться, по нескольким причинам: ожидание окончания ввода-вывода, ожидание получения замка, ожидание пробуждения после Thread.sleep или ожидания окончания вычислений в другом потоке. Когда поток блокируется, он обычно переходит в одно из заблокированных состояний (BLOCKED, WAITING, TIMED_WAITING). Отличие между блокирующей операцией и обычной операцией, которая просто занимает много времени в том, что заблокированный поток должен ждать события, над которым он не имеет контроля - пока IO завершится, замок станет доступным или внешнее вычисление закончится. Когда внешнее событие происходит, поток получает обратно состояние RUNNABLE и становится доступным для планировки к выполнению.

https://carlmastrangelo.com/blog/javas-mysterious-interrupt

Методы put и take в BlockingQueue выбрасывают проверяемое исключение InterruptedException. Так же делают и некоторые другие библиотечные методы, вроде Thread.sleep. TODO:??? И когда заблокированный поток прерывается, мы получаем возможность с помощью этого исключения выполнить какие-то действия, прежде чем поток будет уничтожен \ вернется в пул. TODO:??? Прерывание заблокированного потока означает просто установку бита прерывания у этого потока, и все. Дальше все идет как будто никакого прерывания не было - "прерванный" поток продолжает ждать своей очереди на выполнение и когда она приходит, то метод, вызвавший блокировку (например, Thread.sleep), проверяет бит прерывания и если он установлен, выбрасывается InterruptedException.

Прерывание - это кооперативный механизм. Это значит, что поток А не может просто взять и обрушить поток В. Он может только послать ему сигнал прерваться, а как этот сигнал обрабатывать - дело потока В. Если он не проверяет статус прерывания, то вообще не прервется. Но по-хорошему он должен в некоторых удобных точках проверять этот статус. Большинство блокирующих методов как раз проверяют статус прерывания, завершают свои дела корректно и выбрасывают после этого InterruptedException.

Если в своем коде мы вызываем блокирующий метод, значит наш метод тоже становится блокирующим и мы должны решить, что делать, если получим InterruptedException. Тут обычно два варианта:

* В методах, возвращающих результат, можно повторно выбросить InterruptedException

* В случаях, когда результата нет, например выполняем Runnable, можно выставить флаг прерывания текущего потока, и таким образом сигнализировать вызывающему коду, что этот Runnable остановился. Например:

  ```java
  public class TaskRunnable implements Runnable {
  
      BlockingQueue<Task> queue;
      ...
      public void run() {
          try {
              processTask(queue.take());
          } catch (InterruptedException e) {
              // restore interrupted status
              Thread.currentThread().interrupt();
          }
      }
      
  }
  ```

Обрабатывать прерывание можно как угодно, но никогда не надо *проглатывать* его, т.е. ловить исключение и не делать ничего. Это лишает верхний код какой-либо возможности узнать, что было прерывание.

# 5.5 Syncronizers

Синхронизатор - это объект, который на основе своего состояния координирует ход выполнения потоков. Примерами синхронизаторов являются семафоры, барьеры и защелки (semaphores, barriers, latches). В стандартной библиотеке есть набор готовых классов, но если они вам не подходят, вы можете разработать свои механизмы, используя информацию из главы 14.

У всех синхронизаторов есть нечто общее: они, во-первых, инкапсулируют свое состояние и определяют, может ли поток, обратившийся к синхронизатору, продолжить выполнение или должен заблокироваться; во-вторых, предоставляют методы для управления своим состоянием и методы эффективного ожидания, пока синхронизатор войдет в нужное состояние.

## 5.5.1 Latches

Защелка - это синхронизатор, который задерживает выполнение потоков до тех пор, пока не достигнет своего *терминального* (конечного, лол, объяснил называется) состояния. Защелка действует как заслонка (ворота, сотни переводов, больше подходит как что-то открывающееся вверх), которая в какой-то момент открывается и больше не может быть закрыта (это ключевое свойство - не может быть закрыта, т.е. по сути одноразовая). Используется, когда нужно гарантировать, что какой-то процесс не начнет выполнение, пока некоторые другие процессы не выполнятся до конца.

Чтобы запомнить, что защелка одноразовая и принцип ее действия, можно представить картину зомби-апокалипсиса: у нас есть некоторая крепость с воротами, а вокруг крепости орды зомби. У нас есть основная задача "уничтожить зомби" - это "главный" поток, и есть подзадачи - "собрать людей у ворот", "подготовить оружие", "объяснить план" - это "вспомогательные" потоки. Не выполнив эти мини-задачи, мы не можем начать главный план, потому что без подготовки он провалится. Когда же эти три задачи выполнены, мы открываем ворота и орды зомби хлынут внутрь, мы уже не сможем закрыть ворота (зомби мешают) и начинает выполнение главный поток - "уничтожение зомби".

CountDownLatch является реализацией защелки. Она инициализируется целым положительным числом, защелка передается в "основной" поток и "вспомогательные". Основной поток ожидает, пока защелка не занулится, а вспомогательные уменьшают защелку. Когда она зануляется, основной поток начинает выполнение.

Вот как можно решить с помощью защелки такую задачу: подготовить несколько потоков, которые должны начать выполнение только когда все будут готовы. В главном потоке ждать, пока все потоки будут выполнены:

```java
public class TestHarness {

    public long timeTasks(int nThreads, final Runnable task) throws InterruptedException {
        final CountDownLatch startGate = new CountDownLatch(1);
        final CountDownLatch endGate = new CountDownLatch(nThreads);

        for (int i = 0; i < nThreads; i++) {
            Thread t = new Thread() {
                public void run() {
                    try {
                        startGate.await();
                        try {
                            task.run();
                        } finally {
                            endGate.countDown();
                        }
                    } catch (InterruptedException ignored) { }
                }
            };
            t.start();
        }

        long start = System.nanoTime();
        startGate.countDown();
        endGate.await();
        long end = System.nanoTime();
        return end-start;
    }
    
}
```

Решение достигается за счет двух защелок. Каждый поток начинает свою работу с ожидания "мастер-защелки", которую отпускает главный поток, когда все рабочие потоки подготовлены и запущены. Сам главный поток ожидает "финальную" защелку, которая откроется, когда каждый поток выполнится.

## 5.5.2 FutureTask

FutureTask реализует интерфейс Future и работает как защелка. Она может быть в трех состояниях: ожидание запуска, работа, завершено. Завершение подразумевает любое завершение: успешное, отмененное, исключение. Как только FT входит в состояние завершено, оно остается в нем навсегда.

Поведение Future.get зависит от состояния задачи. Если оно завершено, get возвращает результат немедленно, иначе поток блокируется до тех пор, пока задача не закончится. FT передает результат из выполняющегося потока в вызывающий, гарантируя безопасную публикацию результата.

Подходит для ситуаций, когда можно заранее запустить какое-то вычисление, результат которого нужен не сразу.

```java
public class Preloader {

    private final FutureTask<ProductInfo> future =
        new FutureTask<ProductInfo>(new Callable<ProductInfo>() {
            public ProductInfo call() throws DataLoadException {
                return loadProductInfo();
            }
        });

    private final Thread thread = new Thread(future);

    public void start() { thread.start(); }

    public ProductInfo get() throws DataLoadException, InterruptedException {
        try {
            return future.get();
        } catch (ExecutionException e) {
            Throwable cause = e.getCause();
            if (cause instanceof DataLoadException)
                throw (DataLoadException) cause;
            else
                throw launderThrowable(cause);
        }
    }
    
    public static RuntimeException launderThrowable(Throwable t) {
        if (t instanceof RuntimeException)
            return (RuntimeException) t;
        else if (t instanceof Error)
            throw (Error) t;
        else
            throw new IllegalStateException("Not unchecked", t);
        }
    
}
```

## 5.5.3 Semaphores

Семафоры используются, чтобы управлять количеством активностей, которые одновременно могут получить доступ к определенному ресурсу или выполнить какое-то действие. Семафоры могут использоваться для создания пула ресурсов.

Семафор оперирует *разрешениями* (permits). Начальное количество разрешений передается через конструктор. Активности могут запрашивать разрешения, если еще есть доступные в наличии, и возвращать разрешения, когда работа выполнена. Если доступных разрешений нет, метод aquire блокирует поток до тех пор, пока разрешение не появится. Семафор с единицей называется бинарным семафором и работает как мьютекс.

Семафоры полезны для организации пулов ресурсов, вроде соединений с базой данных. Пример bounded buffer будет в главе 12.

Пример организации коллекции ограниченного размера с помощью семафора:

```java
public class BoundedHashSet<T> {

    private final Set<T> set;
    private final Semaphore sem;

    public BoundedHashSet(int bound) {
        this.set = Collections.synchronizedSet(new HashSet<T>());
        sem = new Semaphore(bound);
    }
    
    public boolean add(T o) throws InterruptedException {
        sem.acquire();
        boolean wasAdded = false;
        try {
            wasAdded = set.add(o);
            return wasAdded;
        }
        finally {
            if (!wasAdded)
                sem.release();
        }
    }

    public boolean remove(Object o) {
        boolean wasRemoved = set.remove(o);
        if (wasRemoved)
            sem.release();
        return wasRemoved;
    }
    
}
```

## 5.5.4 Barriers

В общем тут попытались немножко написать отличие защелок от барьеров:

> Барьеры похожи на защелки в том, что они блокируют потоки до наступления события. Ключевое отличие в том, что в барьере все потоки должны собраться у него в одно и то же время, чтобы продолжить выполнение. Защелки - для ожидания события, барьеры - для ожидания других потоков.

Попытка жиденькая, но написать словами отличие реально сложно, у меня у самого не получилось (попробовать сделать это в конспекте о примитивах синхронизации). На примере понятнее, который там был, я отметил. Сюда писать сейчас не буду, может быть в том конспекте немного переделаю структуру и внесу туда этот момент.

А теперь о полезных дополнениях:

Если при вызове await получается таймаут или какой-то поток, вызвавший await на барьере, прерывается, то барьер становится "сломанным" (broken) и все последующие вызовы await выбрасывают исключение BrokenBarrierException.

После успешного прохождения барьера что-то вот такое написано:

> If the barrier is successfully passed, await returns a unique arrival index for each thread, which can be used to “elect” a leader that takes some special action in the next iteration

Загуглить отдельно и вписать в конспект по примитивам.

Про Exchanger написано два слова и как будто ничего особо интересного, чего нельзя было бы найти в других местах.

Ну и на барьер показан вот этот галимый пример. Как будто слишком много надо додумать, чтобы он сложился:

```java
public class CellularAutomata {

    private final Board mainBoard;
    private final CyclicBarrier barrier;
    private final Worker[] workers;

    public CellularAutomata(Board board) {
        this.mainBoard = board;
        int count = Runtime.getRuntime().availableProcessors();
        this.barrier = new CyclicBarrier(count, new Runnable() {
            public void run() {
                mainBoard.commitNewValues();
            }});
        this.workers = new Worker[count];

        for (int i = 0; i < count; i++)
            workers[i] = new Worker(mainBoard.getSubBoard(count, i));
    }

    private class Worker implements Runnable {
        private final Board board;
        
        public Worker(Board board) { 
            this.board = board; 
        }

        public void run() {
            while (!board.hasConverged()) {
                for (int x = 0; x < board.getMaxX(); x++)
                    for (int y = 0; y < board.getMaxY(); y++)
                        board.setNewValue(x, y, computeValue(x, y));
                try {
                    barrier.await();
                } catch (InterruptedException ex) {
                    return;
                } catch (BrokenBarrierException ex) {
                    return;
                }
            }
        }
    }
    
    public void start() {
        for (int i = 0; i < workers.length; i++)
            new Thread(workers[i]).start();
        mainBoard.waitForConvergence();
    }
    
}
```



# 5.6 Building an efficient, scalable result cache

Разберем на примере кэширования результата, как это можно сделать эффективно. Начнем с наивной реализации и постепенно улучшим ее.

Пусть у нас будет интерфейс и тяжелая функция:

```java
public interface Computable<A, V> {
    V compute(A arg) throws InterruptedException;
}

public class ExpensiveFunction implements Computable<String, BigInteger> {
    public BigInteger compute(String arg) {
        // after deep thought...
        return new BigInteger(arg);
    }
}
```

Создадим обертку, в которую мы могли бы поместить эту тяжелую функцию, чтобы кэшировать в этой обертке результат:

## Первый вариант, самый наивный:

```java
public class Memoizer1<A, V> implements Computable<A, V> {
    
    @GuardedBy("this")
    private final Map<A, V> cache = new HashMap<A, V>();
    private final Computable<A, V> c;

    public Memoizer1(Computable<A, V> c) {
        this.c = c;
    }

    public synchronized V compute(A arg) throws InterruptedException {
        V result = cache.get(arg);
        if (result == null) {
            result = c.compute(arg);
            cache.put(arg, result);
        }
        return result;
    }
    
}
```

Проблема по сути одна: отсутствие масштабируемости. Только один поток за раз может выполнять вычисления. Если они долгие, то быстрее будет вообще ничего не кэшировать, а просто чтобы несколько потоков выполняли расчеты параллельно, пусть даже и для одного значения.

<img src="img/image-20230601110123724.png" alt="image-20230601110123724" style="zoom:80%;" />

## Второй вариант

```java
public class Memoizer2<A, V> implements Computable<A, V> {

    private final Map<A, V> cache = new ConcurrentHashMap<A, V>();
    private final Computable<A, V> c;

    public Memoizer2(Computable<A, V> c) { 
        this.c = c; 
    }

    public V compute(A arg) throws InterruptedException {
        V result = cache.get(arg);
        if (result == null) {
            result = c.compute(arg);
            cache.put(arg, result);
        }
        return result;
    }
    
}
```

Улучшение:

* Теперь несколько потоков могут одновременно работать со словарем.

Недостаток в том, что:

* Несколько потоков могут начать вычисление для одного и того же значения, если первый начавший не успел положить результат в кэш до того, как это же понадобится кому-то еще. В итоге два и более потоков создадут несколько таких объектов и перезапишут работу друг друга. Кроме бесполезной работы, в некоторых случаях это может породить дополнительные проблемы: в более общем случае может быть требование вычислить значение только один раз. Это может быть даже не вычисление, а например создание какого-то объекта, который должен быть создан только один раз. А в итоге два и более потоков создадут несколько таких объектов.

TODO: Не понимаю, в чем отличие конкурентного словаря от обычного в данном случае? Ведь используется операция получения, а не например "добавления-если-отсутствует". Надо посмотреть исходники конкурентного словаря.

<img src="img/image-20230601110139379.png" alt="image-20230601110139379" style="zoom:80%;" />

## Третий вариант

```java
public class Memoizer3<A, V> implements Computable<A, V> {

    private final Map<A, Future<V>> cache = new ConcurrentHashMap<A, Future<V>>();
    private final Computable<A, V> c;

    public Memoizer3(Computable<A, V> c) { 
        this.c = c; 
    }

    public V compute(final A arg) throws InterruptedException {
        Future<V> f = cache.get(arg);
        if (f == null) {
            Callable<V> eval = new Callable<V>() {
                public V call() throws InterruptedException {
                    return c.compute(arg);
                }
            };
            FutureTask<V> ft = new FutureTask<V>(eval);
            f = ft;
            cache.put(arg, ft);
            ft.run(); // call to c.compute happens here
        }
        try {
            return f.get();
        } catch (ExecutionException e) {
            throw launderThrowable(e.getCause());
        }
    }
    
}
```

Улучшение:

* Мы частично сокращаем временное окно, в течение которого несколько потоков могут начать вычисления для одного и того же значения, поскольку мы кладем в словарь не результат, а Future. Получается, что кэш заполняется еще до того, как начинается вычисление. Поэтому, если кому-то понадобится кэш для условной 7, то он из словаря достанет Future и попробует извлечь из него результат. Если результат готов, то поток получит его немедленно. Если не готов, то поток заблокируется и возобновится по готовности результата.

Недостаток:

* Все еще возможен запуск нескольких одинаковых вычислений, поскольку при помещении Future в кэш мы не проверяем, есть ли уже там Future для такого значения или нет. Это может быть, если поток А дошел например до строки `f = ft;` и прервался, а поток В тоже дошел туда, положил свой Future в кэш и потом поток А перезаписывает этот Future своим и снова получается, что параллельно выполняются вычисления для одного и того же значения.
* "Загрязнение" кэша. Если вычисление прервется или сломается, то в кэше останется "сломанный" Future, который будет мешаться, потому что поток, видя наличие Future, не будет создавать еще один, и при этом не сможет получить результат из сломанного Future.

<img src="img/image-20230601113229476.png" alt="image-20230601113229476" style="zoom:80%;" />

## Четвертый вариант, четкий

```java
public class Memoizer<A, V> implements Computable<A, V> {

    private final ConcurrentMap<A, Future<V>> cache = new ConcurrentHashMap<A, Future<V>>();
    private final Computable<A, V> c;

    public Memoizer(Computable<A, V> c) { 
        this.c = c; 
    }

    public V compute(final A arg) throws InterruptedException {
        while (true) {
            Future<V> f = cache.get(arg);
            if (f == null) {
                Callable<V> eval = new Callable<V>() {
                    public V call() throws InterruptedException {
                        return c.compute(arg);
                    }
                };
                FutureTask<V> ft = new FutureTask<V>(eval);
                f = cache.putIfAbsent(arg, ft);
                if (f == null) { 
                    f = ft; 
                    ft.run(); 
                }
            }
            try {
                return f.get();
            } catch (CancellationException e) {
                cache.remove(arg, f);
            } catch (ExecutionException e) {
                throw launderThrowable(e.getCause());
            }
        }
    }
    
}
```

Не понял, зачем while. UPD. Понял - чтобы убрать загрязнение кэша.

Улучшение:

* Избавились от возможного двойного расчета для одного и того же входа. putIfAbsent, если нет такого, возвращает null, а если есть - то значение. Таким образом, даже если два потока посчитают, что в кэше пусто, и создадут два Future, то при непосредственной попытке положить свой Future в кэш, тот кто попытается сделать это вторым номером, просто получит Future того, кто успел его туда положить первым.

* Избавились от загрязнения кэша. Теперь при попытке получить результат из сломанного Future, поток с помощью обработки исключения уберет его из кэша, а за счет while проведет всю операцию заново, т.е. создаст новый Future, а после вычисления вернет результат и т.о. выйдет из while.

  

Применение кэша к сервлету, рассчитывающему факториал:

```java
@ThreadSafe
public class Factorizer implements Servlet {

    private final Computable<BigInteger, BigInteger[]> c = 
        new Computable<BigInteger, BigInteger[]>(){
            public BigInteger[] compute(BigInteger arg) {
                return factor(arg);
            }
        };

    private final Computable<BigInteger, BigInteger[]> cache = 
        new Memoizer<BigInteger, BigInteger[]>(c);

    public void service(ServletRequest req, ServletResponse resp) {
        try {
            BigInteger i = extractFromRequest(req);
            encodeIntoResponse(resp, cache.compute(i));
        } catch (InterruptedException e) {
            encodeError(resp, "factorization interrupted");
        }
    }
    
}
```



# Выводы к Части 1

* Все проблемы конкурентности сводятся к координированию доступа к изменяемому состоянию. Чем меньше изменяемого состояния, тем проще обеспечить потокобезопасность (ПБ).
* Объявляйте поля final, если не подразумевается их изменять.
* Неизменяемые объекты ПБ по своей природе. Они чрезвычайно упрощают конкурентное программирование, поскольку не требуют защитного копирования и поэтому ими проще "делиться" между многими потоками.
* Инкапсуляция позволяет управлять сложностью. Инкапсуляция данных внутри объекта упрощает сохранность инвариантов. Инкапсуляция синхронизации внутри объекта упрощает размышления о политике их использования в конкурентной среде.
* Охраняйте каждую изменяемую переменную с помощью замка.
* Охраняйте одним и тем же замком все переменные, относящиеся к одному и тому же инварианту.
* Удерживайте замки на протяжении всего *составного* действия.
* Программа, которая обращается к изменяемой переменной из нескольких потоков и не использует для этого синхронизацию - сломанная программа.
* Не полагайтесь на размышления "почему мне не нужна синхронизация"
* Продумывайте ПБ на этапе проектирования или явно документируйте факт, что ваш класс не ПБ.
* Документируется вашу политику синхронизации.