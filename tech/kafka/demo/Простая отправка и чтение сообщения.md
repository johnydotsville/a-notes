# Docker

Поднимаем кафку в докере. Для этого:

* В любом месте создаем обычный текстовый файл с настройками для docker-compose, например `kafka_settings.yaml` и помещаем в него конфиг (взят из конспекта по настройке брокера, там же объяснения, если вдруг надо).
* Открываем виндовую консоль или powershell, переходим в директорию с конфигом и выполняем команду `docker-compose -f "kafka_settings.yml" up` При этом докер скачает образы, поднимет контейнеры и можно двигаться дальше.

Конфиг:

```yaml
version: '2'

services:

# ========================= ZooKeeper section ========================= #

  # ========== Zookeper A ========== #

  zookeeper-1:
  
    image: confluentinc/cp-zookeeper:latest
    
    container_name: my-zookeeper-1
    
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      
    ports:
      - 22181:2181

  # ========== Zookeper B ========== #      
      
  zookeeper-2:
  
    image: confluentinc/cp-zookeeper:latest
    
    container_name: my-zookeeper-2
    
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      
    ports:
      - 22182:2181

# ========================= Kafka section ========================= #

  # ========== Broker A ========== #

  broker-1:
  
    image: confluentinc/cp-kafka:latest
    
    container_name: my-broker-1
    
    depends_on:
      - zookeeper-1
      - zookeeper-2
      
    ports:
      - 49092:49092
    
    environment:
    
#      KAFKA_BROKER_ID: 1  # Не обязательно, если не задан, то автогенерация
      
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181,zookeeper-2:2181
      
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      
      KAFKA_LISTENERS: INSIDE://broker-1:9092,OUTSIDE://broker-1:49092
      
      KAFKA_ADVERTISED_LISTENERS: INSIDE://broker-1:9092,OUTSIDE://localhost:49092
      
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"


  # ========== Broker B ========== #

  broker-2:
  
    image: confluentinc/cp-kafka:latest
    
    container_name: my-broker-2
    
    depends_on:
      - zookeeper-1
      - zookeeper-2
      
    ports:
      - 49093:49092
    
    environment:
    
#      KAFKA_BROKER_ID: 2  # Не обязательно, если не задан, то автогенерация
      
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181,zookeeper-2:2181
      
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      
      KAFKA_LISTENERS: INSIDE://broker-2:9092,OUTSIDE://broker-2:49092
      
      KAFKA_ADVERTISED_LISTENERS: INSIDE://broker-2:9092,OUTSIDE://localhost:49093
      
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
```

# Kafka Tool

В программе Offset Explorer добавляем новый кластер и вводим данные для соединения с зукипером и кафкой, которые на предыдущем шаге мы подняли в докере:

* Вкладка Properties:
  * cluster name - любой
  * Zookeeper Host - зукипер крутится в докере на нашем компьютере, поэтому указываем именно наш компьютер (localhost).
  * Zookeeper Port - в конфиге мы подняли два инстанса зукипера и связали их с портами 22181 и 22182 хоста. Берем любой из них, например 22181.
* Вкладка Advanced:
  * Bootstrap Servers - здесь нужно указать брокер кафки. Мы подняли в докере два брокера и связали их с портами 49092 и 49093 хоста. Указываем любой из этих брокеров, например localhost:49093.

Затем тут же создаем новый топик с любым именем, например, *mytopic*.

# Spring

Программа из папки kafka-spring.

## Зависимости

Заходим на `start.spring.io` и добавляем там зависимость `Spring for Apache Kafka`. Скачиваем архив, распаковываем и в pom у нас будет нужная зависимость для работы с кафкой:

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```

Версию не указываем, иначе могут быть проблемы с совместимостью. Без указания возьмется гарантированно рабочая из подборки самого спринга.

## Настройки

Добавим в src/main/resources в файл application.properties адрес сервера кафки (тот, который настраивали в докере):

```json
spring.kafka.bootstrap-servers=localhost:29092
```

## Конфигурируем продюсера и консюмера

Конфигурация продюсера:

```java
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaProducerConfig {
    
    @Value(value = "${spring.kafka.bootstrap-servers}")  // Адрес сервера кафки берем из настроек
    private String bootstrapAddress;

    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();

        configProps.put(
                ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,
                bootstrapAddress);
        configProps.put(
                ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
                StringSerializer.class);
        configProps.put(
                ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
                StringSerializer.class);

        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
    
}
```

Конфигурация консюмера:

```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;

import java.util.HashMap;
import java.util.Map;

@EnableKafka
@Configuration
public class KafkaConsumerConfig {
    
    @Value(value = "${spring.kafka.bootstrap-servers}")  // Адрес сервера кафки берем из настроек
    private String bootstrapAddress;

    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> props = new HashMap<>();

        props.put(

                ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,
                bootstrapAddress);
        props.put(
                ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,
                StringDeserializer.class);
        props.put(
                ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,
                StringDeserializer.class);

        return new DefaultKafkaConsumerFactory<>(props);
        
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());

        return factory;
    }
    
}
```

## Пишем продюсера и консюмера

### Продюсер

```java
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

@Component
public class Producer {
    
    private KafkaTemplate<String, String> kafka;

    @Autowired
    public Producer(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafka = kafkaTemplate;
    }

    public void send(String topic, String message) {
        kafka.send(topic, message);
    }
    
}
```

Здесь продюсер по сути - простая обертка над объектом KafkaTemplate.

### Консюмер

```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

@Component
public class Consumer {
    
    @KafkaListener(topics = "mytopic", id = "listener1")
    public void read(String message) {
        System.out.println("Событие прочитано: " + message);
    }
    
}
```

Здесь может смутить наличие параметра message у метода чтения. Но консюмер устроен таким образом, что *автоматически* читает сообщения по мере их поступления. Т.е. метод read нам не придется нигде явно вызывать и этот параметр, соответственно, инфраструктурный, мы с ним имеем дело исключительно внутри метода чтения.

## Проверяем как работает

```java
@SpringBootApplication
public class App {
    
    public static void main(String[] args) {
        ApplicationContext context = SpringApplication.run(App.class, args);

        Producer helper = (Producer) context.getBean("producer");
        String topic = "mytopic";
        String message = "Hello, kafka!";
        helper.send(topic, message);
    }
    
}
```

Если все успешно, то в Offset Explorer в топике появится сообщение, а в консоли idea мы увидим строку "Сообщение прочитано: Hello, kafka!". Консюмер прочитал отправленное нами сообщение автоматически, мы не вызывали явно никаких методов чтения.