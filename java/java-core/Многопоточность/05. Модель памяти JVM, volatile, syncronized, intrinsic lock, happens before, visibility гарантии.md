# Вопросы

- [x] Как устроена модель памяти JVM и как она ложится на физическую память компьютера? 
  - [x] Где в физической памяти может располагаться стек и куча? Например, может ли куча располагаться в регистрах процессора?
  - [x] Сколько вообще может быть стеков и сколько куч? Как они распределяются между потоками?
  - [x] Где хранятся такие вещи как объекты, статические поля классов, локальные переменные методов и параметры методов?
- [x] В чем заключаются такие системные оптимизации как отложенная запись, кэширование данных и команд, изменение порядка команд?
  - [x] Могут ли они навредить однопоточной\многопоточной программе и если да, то как?
  - [x] Как они влияют на команды чтения\записи?
- [x] К чему применим модификатор volatile? Защищает ли он от race condition и почему? 
  - [x] Будет ли *i++* атомарной операцией, если i является volatile?
- [x] К чему применим модификатор syncronized?
  - [x] Что такое intrinsic lock и reentrancy и как это связано с syncronized? 
  - [x] Когда захватывается и когда освобождается лок? Что будет с локом, если возникнет исключение?
  - [x] Можно ли (и нужно ли) использовать разные локи для блокировки одного и того же набора данных?
  - [x] Может ли статический метод быть синхронизированным? Если да, что в таком случае служит замком?
- [x] У объекта есть два синхронизированных метода - А и В. Если один поток выполняет метод А, то может ли другой поток параллельно выполнять метод В? Как это работает? А если метод синхронизирован не целиком, а только его часть?
- [x] Что такое happens-before и visibility гарантии?
  - [x] Что именно они означают для syncronized и volatile?
  - [x] Если у класса несколько обычных полей и одна волатилька, то какой эффект на обычные поля окажет чтение\запись волатильки?
  - [x] Можно ли использовать общие данные вне блока синхронизации? Возможны ли какие-нибудь негативные последствия от такого использования? Какой эффект оказывает на них вход\выход из синхронизированного блока?
- [x] Какая особенность есть у типов long и double и как volatile и syncronized при этом помогают?

# Модель памяти JVM

В общих чертах модель памяти JVM и ее связь с физической памятью компьютера выглядит так:

![jvm-memory-model.drawio](img/jvm-memory-model.drawio.svg)

А описать ее можно следующими утверждениями:

* У каждого потока - свой стек
* Куча - общая
* Объекты *всегда* хранятся в куче
* Статические поля классов - тоже хранятся в куче
* Локальные переменные методов и параметры методов - хранятся в стеке. Если они при этом являются объектами, то в стеке хранится только *ссылка* (т.е. сама переменная), а ее *значение* (т.е. сам объект) - в куче

Это логическая модель памяти JVM. Физически же получается, что:

* Данные из стека\кучи могут лежать где угодно - в регистрах процессора, в кэше, в оперативке. Например, объект при создании попадает в оперативку, а потом при использовании для скорости копируется в кэш и лежит там непредсказуемое время
* Из-за этого объект, который лежит в куче и логически должен видим как единственный обоим тредам, в результате копируется в кэш каждого ядра (прим., если конечно треды выполняются на разных ядрах) и получается уже два независимых объекта. И когда пойдет синхронизация кэша и оперативки, одна копия обязательно затрет другую

# Опасные оптимизации

Процессор и сама JVM могут выполнять различные оптимизации, как например:

* Отложенная запись - когда команды записи данных выполняются не сразу же как возникли, а ставятся в очередь и потом выполняются разом
* Изменение порядка команд (reordering) - иногда с точки зрения процессора\JVM последовательность команд не критична и когда они видят, что можно выполнить оптимальнее, то могут выполнить команды программы не в том порядке, в котором мы их написали. Например, какие-нибудь последовательные команды присвоения
* Кэширование данных и команд - во время работы процессоры наполняют свой кэш данными и командами, чтобы не обращаться за ними в оперативку. А поскольку у каждого ядра собственный кэш, то если два потока используют общие данные, но выполняются на разных ядрах, то у каждого потока будет своя копия этих данных в кэше. Они будут менять\читать эти данные, каждый свою копию, и понятия не иметь о том, что делает с данными "сосед".

В многопоточных приложениях это может вызывать трудноуловимые ошибки. Грубый пример:

```java
public class TaskRunner {

    private static int number;
    private static boolean ready;

    private static class Reader extends Thread {

        @Override
        public void run() {
            while (!ready) {
                Thread.yield();
            }

            System.out.println(number);
        }
    }

    public static void main(String[] args) {
        new Reader().start();
        number = 42;
        ready = true;
    }
}
```

Если поменять местами присвоение значений в ready и number, параллельный поток может вывести нам 0 вместо 42. И прочие неожиданности. Поэтому в джаве есть специальные средства, чтобы таких проблем не было.

# Гарантии

В однопоточных программах упомянутые оптимизации проблем не вызывают (я надеюсь), иначе вряд ли бы вообще они применялись. А в многопоточных - вызывают. Поэтому для многопоточной работы придумали механизмы, которые позволяют эти оптимизации отключать\обходить их эффекты.

## happens-before гарантия

Представим что где-то хранятся данные и флаг их готовности и, опять же, "где-то" находятся методы их заполнения и использования (как именно эти фрагменты разнесены по классам и связаны, для понимания сути не критично. Например, это может быть три класса - "данные", "генератор" и "потребитель" или только два - не важно):

> Предупреждение, пример и объяснение я придумал сам, исходя из текущего уровня понимания, нет гарантий, что я прав

```java
...
    private int number;
    private boolean ready;  // <-- Здесь могла бы быть ваша реклама... volatile
... 
	public void compute() {
        ready = false;
        number = rand.nextInt(100) + 1;  // <-- Или эти две строчки могли бы
        ready = true;                    // <-- быть обернуты в syncronized
    }
...
    public void print() {
        if (!ready)
            return;
        sout(number);
    }
 ...
```

В однопоточной программе в методе compute в общем-то не важно, какая строчка выполнится первой `number = rand.nextInt(100) + 1` или `ready = true`, т.к. в любом случае анализ ready не может случиться до записи в number из-за линейной природы однопоточки. Поэтому JVM их вполне может переставить, если это будет выгодно для оптимизации (мб ей проще подряд записать две bool-переменных например. Хотя конечно в однопоточке смысла делать флаг готовности вообще нет)

Но для многопоточной именно существующий порядок критичен для правильной работы. Потому что если сначала установить флаг, а потом - значение, то может случиться, что поток А, выполняющий метод compute(), будет вытеснен сразу после установки флага в true, не успев заполнить данные. Тогда поток В, выполняющий метод print(), получит ready == true, хотя на самом деле это ошибка, ведь данные еще не готовы.

В многопоточных программах нельзя заранее назвать последовательность, в которой будет выполняться код. Мы запускаем два потока - один заполняет, другой читает, но не можем знать, кто из них пойдет на выполнение первым. Более того, мы не можем знать, в какой момент каждый из этих потоков будет вытеснен (т.е. на какой команде он прервется), чтобы дать поработать другому.

Поэтому о многопоточной программе нужно думать как о *последовательности событий* и понимать, что важно не то, *когда* именно выполнится какая-то команда, а то, *какую позицию* она займет среди других команд. По примеру выше, нам важно, чтобы ready = false произошло *до* присвоения нового значения, а присвоение нового значения произошло *до* ready = true. При этом нам становится не важно что в любой момент между этими операциями процесс может приостановиться, и какой-то другой процесс проверит значение ready.

Поэтому и придумали т.н. **"happens-before"** гарантию. Она записывается так:

```java
hb(x, y) // "x произошло до y"
hb(y, z)
=> hb(x, z)
```

Стандартная естественная логика - если *x* произошло до *y*, а *y* в свою очередь произошло до *z*, то значит и *x* произошло до *z*.

Для многопоточных программ hb означает уверенность в том, что, несмотря на оптимизации и вытеснение, общий ход событий будет корректным.

## visibility гарантия

Можно охарактеризовать так: несколько потоков при чтении\записи *общих данных* должны работать с актуальными данными, независимо от технических деталей.

# volatile

Модификатор volatile применяется к полям класса (к локальным переменным - нет, исключительно к полям).

Волатильность (volatile - "изменчивый, непостоянный") - это про данные. Поскольку процессор\ядро работают каждый со своей кэш-памятью, а в оперативку пишут\читают от случая к случаю, то если два потока будут работать на разных ядрах, это может привести к таким проблемам:

* Для записи это значит, что новое значение D может осесть в кэше, и когда оно перенесется в оперативку - доподлинно не известно. Важно, что не сразу, а это проблема, потому что другой поток вероятно хотел бы прочитать это новое значение
* Для чтения это значит, что при попытке узнать значение D, оно будет взято из кэша, а не из оперативки. То есть если даже в первом случае получилось так, что новое значение все-таки попало в оперативку "оперативно", то это не важно, потому что чтение все равно произвелось из кэша

Так вот, применение к данным D модификатора volatile приводит к тому, что при записи D, новое значение гарантированно попадает в оперативку "оперативно", а при чтении берется из оперативки, а не из кэша. Это еще называют иногда "пробитие кэша". Как на самом деле на техническом уровне это реализовано - то ли кэш синхронизируется с оперативкой, то ли данные пишутся\читаются сразу из оперативки - не важно. Важно то, что проблема несогласованности именно из-за кэширования больше не возникает.

Однако проблему race condition волатильность сама по себе не решает. Модификатор volatile сам по себе не делает операции над волатильными переменными атомарными. Он лишь гарантирует, что при операции `i = 7` семерка самым скорым образом попадет в оперативку. Эта простая операция, которая по своей природе является атомарной. Но если операция более сложная, `i += 7`, то она уже не атомарная (прочитать старое значение - прибавить 7 - записать новое), а значит может прерваться на любом из этих трех шагов и возникнет race condition.

## volatile и гарантии happens-before и visibility

> В этой теме есть риск закопаться глубже, чем она того заслуживает. Поэтому я сделал только краткое описание. Но если вдруг будет ощущение, что чего-то не хватает, всегда можно начать раскопки [отсюда](https://jenkov.com/tutorials/java-concurrency/volatile.html)

У волатилек есть особенность по части видимости: они влияют не только на свою видимость, но и на видимость обычных полей. Например:

```java
...
    private int hours;
    private int years;
    private int months
    private volatile int days;
...
    public void update(int years, int months, int days, int hours){
        this.years  = years;   // Пробитие кэша "за компанию"
        this.months = months;  // Пробитие кэша "за компанию"
        this.days   = days;    // Пробитие кэша, потому что волатилька
        this.hours  = hours;  // <-- ??? Про это поле будет написано в выводах
    }
...    
    public int totalDays() {
        int total = this.days;
        total += months * 30;
        total += years * 365;
        return total;
    }
...
```

В целом, волатилька дает такие эффекты:

* Visibility: (метод update) при записи волатильки this.days, новые значения years и months тоже будут записаны в оперативку, хотя сами они не волатильные (метод update). Этот эффект называется full visibility.

  (метод totalDays) При чтении волатильки все остальные поля тоже будут перечитаны из оперативки и т.о. будут хранить свежие данные.

* Happens-before: Волатилька не дает перегруппировке команд откровенно сломать программу за счет того, что ограничивает возможности перегруппировки.

  Там довольно хитрый набор правил, вот одно из них: команды чтения\записи не могут при перегруппировке оказаться после записи волатильки, если в исходном коде написаны перед ней. Т.е. команды записи в this.years и this.months гарантированно будут happens-before записи в days, но при этом могут поменяться друг с другом местами, сначала this.month, потом this.years. "Все, что до волатильки - меняй как хочешь, но чтобы ничего из этого не попало за нее".

:question: А вот насчет поля hours есть серьезные вопросы. Раз оно идет после записи волатильки, то распространяется ли на нее эффект full visibility - будет ли this.hours записана в оперативку или рискует осесть в кэше? И может ли эта строчка после перестановки команд оказаться до волатильки? Если да, то сработает ли full visibility эффект?

Найти ответы оказалось трудно, так что эти вопросы остались без ответа. Но в целом среди уважаемых людей бытует мнение, что на все эти правила не стоит сильно полагаться именно из-за потенциальной путаницы и в "Concurrency на практике" явно написано, что волатильки стоит использовать только в случаях, когда эффект однозначно понятен. Итого, я бы выделил такие сценарии:

* Волатильные переменные удобны и часто используются в качестве флажка завершения, прерывания или статуса. Эффект понятен - команда чтения\записи волатильного флажка, во-первых, гарантированно пробьет кэш и, во-вторых, не будет некорректно перегруппирована с другими командами
* Записи в переменную не зависят от ее текущего значения, либо есть гарантия, что значения переменной обновляются только одним потоком. Эффект понятен - команда `i = 7` не зависит от текущего значения i, а `i++` - зависит, поэтому если два потока будут делать i++, неизбежно возникнет race condition. Если пишет только один поток, тогда проблемы rc нет, но есть проблема неактуальных данных: операция прибавления выполнилась, но новое значение не успело записаться и кто-то поэтому прочитал старое значение. Но если чтение таких "недообновленных" данных не читается за проблему, то волатилька сгодится. Если проблема - тогда уже нужна синхронизация

Волатильки снижают производительность, поскольку ограничивают оптимизации, поэтому использовать их стоит только когда их особенности действительно полезны для программы.

# syncronized, intrinsic lock

Синхронизация - это про код. Она нужна для обозначения границ критических секций. В этом случае только один поток может выполнять код КС.

## intrinsic lock

В джаве у *каждого объекта* есть так называемый `intrinsic lock` (альтернативное название - monitor lock), "внутренний замок\внутренняя блокировка" - некая внутренняя вспомогательная структура, которая используется для синхронизации.

> Я надеюсь, что intrinsic lock и monitor lock - это синонимы. Из [доки](https://docs.oracle.com/javase/tutorial/essential/concurrency/locksync.html) однозначно не понятно, так это или нет, да и нагуглить на верочку не удалось

Важно понимать, как именно работает блокировка с помощью intrinsic lock: у каждого объекта - один лок и если тред захватывает этот лок, то пока он его не освободит, никакой другой тред этот же лок захватить не сможет. В примерах ниже важность этого момента объяснена на практике:

Модификатор syncronized применяется только к методам и блокам кода:

* В случае объявления **синхронизированных методов**, intrinsic lock используется неявно:

  ```java
  public class SynchronizedCounter {
      private int c = 0;
  
      public synchronized void increment() {  // <-- Неявно используется intrinsic lock
          c++;
      }
  
      public synchronized void decrement() {  // <-- Неявно используется intrinsic lock
          c--;
      }
  
      public synchronized int value() {  // <-- Неявно используется intrinsic lock
          return c;
      }
      
      public void doSome() {
          System.out.println("Несинхронизированный метод для примера");
      }
  }
  ```

  Допустим, тред А начинает выполнять метод increment. Этот метод синхронизированный, значит А захватывает лок объекта SynchronizedCounter. Допустим, этот метод не успел выполниться до конца, и некий тред В хочет выполнить метод value. Этот метод тоже синхронизированный, значит треду В нужно захватить лок. Но лок уже занят тредом А, так что тред В останавливается и будет ждать освобождения лока. Пусть тред С хочет выполнить метод doSome. Этот метод не синхронизированный, поэтому треду С не нужно захватывать лок, а значит он спокойно выполняет метод.

  Таким образом делаем вывод, что из всех *синхронизированных* методов объекта может выполняться только один за раз, в том смысле, что параллельно они выполняться не могут, т.к. используют для синхронизации *один и тот же лок*.

  ```java
  // Синхронизированный метод аналогичен такой конструкции:
  public void someMethod() {
      syncronized(this) {
          // Всё тело метода
      }
  }
  ```

* В случае **синхронизированных блоков**, мы синхронизируем не весь метод, а только какой-то его фрагмент (или несколько фрагментов) и должны явно указать объект, intrinsic lock которого нужно использовать:

  ```java
  public void addName(String name) {
      // Здесь может быть еще какой-то код
      synchronized(this) {  // <-- Текущий объект, как и любой объект, имеет собственный intrinsic lock
          lastName = name;
          nameCount++;
      }
      nameList.add(name);
  }
  ```

  Или вот так:

  ```java
  public class MsLunch {
      private long c1 = 0;
      private long c2 = 0;
      private Object lock1 = new Object();
      private Object lock2 = new Object();
  
      public void inc1() {
          // Здесь может быть еще какой-то код
          synchronized(lock1) {  // <-- Используем лок объекта lock1 для синхронизации
              c1++;
          }
      }
  
      public void inc2() {
          // Здесь может быть еще какой-то код
          synchronized(lock2) {  // <-- Используем лок другого объекта, lock2, для синхронизации
              c2++;
          }
      }
  }
  ```

  Этот пример примечателен тем, что здесь показано как для синхронизации используются разные объекты, в результате чего у нас получается два синхронизированных, но независимых друг от друга, блока. Если какой-то тред выполняет метод inc1(), то другой тред легко может выполнять inc2()

  Более интересная ситуация, если тред А выполняет метод inc1(), а тред В решит выполнить его же, то они вполне могут выполнять inc1() параллельно, но только до того момента, пока один из них не достигнет строчки 9. Тогда он возьмет себе лок и второй тред будет вынужден ждать освобождения лока, прежде чем продолжить.

В этих примерах замки всегда были внутри того же класса, где они используются: в качестве замка использовался либо сам текущий объект, либо его поля. Более интересный и практичный пример - в конспекте про состояния потоков, там разобрана задача продюсера\консюмера на методах wait(), notify()

## Синхронизированные static методы

Статический метод тоже может быть синхронизированным. Когда программа доходит до использования какого-то класса, то в память загружается объект (тип Class) этого класса. Этот объект и используется в качестве лока при вызове static syncronized методов:

```java
public class StaticSyncMethodDemo() {
    public static syncronized void someMethod() {
        ...
    }
}

// Аналог
public class StaticSyncMethodDemo() {
    public static void someMethod() {
        syncronized (StaticSyncMethodDemo.class) {
            ...
        }
    }
}
```

## Правила синхронизации

* Синхронизацию одних и тех же полей нужно организовывать через один и тот же лок. Если в одном месте для работы с полем `f` используется лок `a`, то и во всех остальных местах работы с f должен использоваться только лок a.

## Освобождение лока

Лок освобождается, когда:

* Весь код в методе или блоке успешно выполняется
* Мы вылетаем из метода\блока с исключением. И даже если исключение не поймано, все равно лок освобождается

## reentrancy

Еще один важный момент: тред, который взял лок, может взять его повторно. Допустим, когда из одного синхронизированного метода вызывается другой синхронизированный метод. Если бы тред не мог этого сделать, то он бы просто завис. А так он просто берет его повторно и как бы "растет счетчик взятий" лока. А по мере освобождения, этот счетчик падает. Так что в итоге лок освобождается, дойдя до 0.

## Смешение sync и не-sync кода

Из синхронизированного блока лучше не вызывать другие методы объекта, если они не синхронизированные. Потому что параллельно этот же метод может вызвать другой поток и результаты перемешаются.

## syncronized и гарантии happens-before и visibility

* Visibility: в момент входа в синхронизированный блок, все поля обновляются из оперативки. В момент выхода из синхронизированного блока, все поля записываются в оперативку.

  Исходя из этих правил и конкретной ситуации и следует поступать. Куцые примеры здесь только запутают, а хороший пример был бы большой и я его сейчас не могу даже придумать. Исходя из логики, можно сделать пару выводов: с общими данными нужно работать только в синхронизированном блоке. Во-первых, это гарантирует их перечитывание из оперативки, значит текущий поток получает свежее. Во-вторых, это гарантирует их запись в оперативку - значит остальные потоки получат свежее. В-третьих, разные потоки не затрут работу друг друга в случае записи, поскольку синхронизация не позволит им одновременно модифицировать одни и те же поля (если конечно синхронизация выполнена правильно)

* Happens-before: здесь правило, насколько я понял, такое - команды не могут перемешиваться на границах блока. Т.е. если какая-то команда стоит непосредственно перед\после блока синхронизации, то она после перегруппировки не может оказаться внутри\вне блока. Ну и наоборот - команда в самом начале\конце блока не может оказаться за его пределами.

# Некоторые тонкости

## long, double и многопоточность

Эти типы занимают 64 бита и операции их чтения\записи не являются атомарными, т.к. состоят из двух операций чтения\записи по 32 бита. Из-за этого в многопоточных программах могут быть проблемы. Чтобы их избежать, нужно объявлять поля этих типов волатильными. Либо использовать их только в синхронизированных блоках.